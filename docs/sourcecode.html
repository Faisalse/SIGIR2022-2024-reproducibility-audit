

<style>
	.box {
	  width: 1200px;        
	  margin: 80px auto 0 auto;
	  padding: 0px;
	  margin: -10px auto 0 auto;
	  text-align: center;
	}
		td {
			border: 1px solid #ffffff;
			padding: 12px;
			text-align: center;
			}

		th {
			background-color: #102E50;
			color: #e6dcdc;
			font-weight: bold;
			}

		tr:nth-child(even) {
			background-color: #f9f9f9;
			}

		tr:hover {
			background-color: #e0f7fa;
			}
		.table-responsive {
		overflow-x: auto;
		-webkit-overflow-scrolling: touch;
		}

		table {
		width: 100%;
		border-collapse: collapse;
		margin: 20px auto;
		
		color: #333;
		min-width: 600px;
		}
</style>		

<div style="display: flex; justify-content: center; gap: 20px; text-align: center; padding: 30px;">
					<div>
						<div>Faisal Shehzad</div>
						<div>faisal.shehzad@aau.at</div>
						<div>University of Klagenfurt, Austria</div>
					</div>
					<div>
						<div>Timo Breuer</div>
						<div>timo.breuer@th-koeln.de</div>
                        <div>TH Köln (University of Applied Sciences), Germany</div>
					</div>
                    <br/>
					<div>
						<div>Maria Maistro</div>
						<div>mm@di.ku.dk</div>
						<div>University of Copenhagen, Denmark</div>
					</div>
					<div>
						<div>Dietmar Jannach</div>
						<div>dietmar.jannach@aau.at</div>
                        <div>University of Klagenfurt, Austria</div>
					</div>
				</div>
        
<div class="box">

	<p align="justify">Graph Neural Networks (GNNs) have shown impressive performance in various domains. Motivated by this success, several GNN-based session-based recommender systems (SBRS) have been proposed over the past few years. The literature suggests that these
							algorithms can achieve strong performance and outperform well established baseline neural models. However, some recent reproducibility studies suggest that the performance achieved by more
							complex GNN-based models may sometimes be overstated and that these models may not be as impactful as expected. Moreover, an
							inconsistent choice of datasets, preprocessing steps, and evaluation protocols across published works makes it difficult to reliably assess
							progress in the field. In this present study, we reassess the performance of three well-established baseline models—GRU4Rec, NARM,
							and STAMP—and compare them to six more recent GNN-based SBRS within a standardized evaluation framework. Experiments
							on commonly used datasets for SBRS reveal that in particular the GRU4Rec model, if properly tuned, is still highly competitive and leads to the best results on two out of three datasets. Furthermore,
							we find that the performance of the GNN-based models varies largely across datasets. Interestingly, only the quite early SR-GNN
							model turns out to be superior in terms of accuracy metrics on one of the datasets. Overall, we speculate that the reasons for our
							surprising result may lie in insufficient hyperparameter tuning processes for the baselines in the original papers.
						</p>
                            
							
						<a href="https://github.com/Faisalse/SIGIR2022-2024-reproducibility-audit/tree/main" class="icon brands fa-github" style="font-weight: bold;">  GitHub: Python script and Statistics from the collected papers</a>
	<p align="justify">
		
	
	
</div>
		
		



	